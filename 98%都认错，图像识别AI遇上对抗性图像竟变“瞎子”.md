## 98%都认错，图像识别AI遇上对抗性图像竟变“瞎子”

[新智元](javascript:void(0);) *昨天*

![img](https://mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb0xicN7hTl7ZDbUdaJkX6iauJEyWibPHnwYRhDYjcb2Bs2xicyynPY0PSyB4mlojY4xAwRZhyUUHm84zQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



###    **新智元报道**  

来源：theverge

编辑：张佳、大明

##### **【新智元导读】**在视觉方面，AI和人类的差距有多大？来自UC Berkeley等高校的研究人员创建了一个包含7500个“自然对抗实例”的数据集，在测试了许多机器视觉系统后，发现AI的准确率下降了90%！在某些情况下，软件只能识别2%-3%的图像。这样的AI若用在自动驾驶汽车上，后果不敢想象！



近几年来，计算机视觉有了很大的改善，但仍然有可能犯严重的错误。犯错如此之多，以至于有一个研究领域致力于研究AI经常误认的图片，称为“**对抗性图像**”。可以把它们看作计算机的光学错觉，当你看到树上有一只猫时，人工智能看到了一只松鼠。



![img](https://mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb0xicN7hTl7ZDbUdaJkX6iauJ8VcjXnltxg1mkoqicDL4to125uCk659MRqlgJjpApfDibnX7Bv8xL1tw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

AI把爬上树的猫误认为松鼠

 

研究这些图像是很有必要的。当我们把机器视觉系统放在AI安全摄像头和自动驾驶汽车等新技术的核心位置时，我们相信计算机和我们看到的世界是一样的。而对抗性图像证明并非如此。

 

## **对抗性图像利用机器学习系统中的弱点**



但是，尽管这个领域的很多关注点都集中在那些专门设计用来愚弄AI的图片上（比如谷歌的算法把3D打印的乌龟误认为是一把枪），但这些迷惑性图像也会自然的出现。这类图像更令人担忧，因为它表明，即便不是我们特意制作的，视觉系统也会犯错。



![img](https://mmbiz.qpic.cn/mmbiz_gif/UicQ7HgWiaUb0xicN7hTl7ZDbUdaJkX6iauJMIrMsZZMFK0gwP9ZrmKKuFYrZc33jwuFm4VjqsrGPBm5dKxKicL0yRQ/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1)

谷歌AI误认为这只乌龟是枪

 

为了证明这一点，来自加州大学伯克利分校、华盛顿大学和芝加哥大学的一组研究人员创建了一个包含7500个“自然对抗实例”（natural adversarial examples）的数据集，他们在这些数据上测试了许多机器视觉系统，发现它们的**准确率下降了90%，在某些情况下，软件只能识别2%-3%的图像。**

 

下面就是一些“自然对抗实例”数据集的例子：



![img](https://mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0xicN7hTl7ZDbUdaJkX6iauJnYGDlqxicq63qR7BYVVgaedjHDFRsBll52gLMV7uMUANibdA38BmmvGA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

AI眼中是“沉船”，其实是虫子爬在枯叶上



![img](https://mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0xicN7hTl7ZDbUdaJkX6iauJZwxNgcoSmv11DHeDa07gDEGX2Z1O69QDcYWbCcedywOFJpLN8Lhnng/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

AI眼中是“火炬”



![img](https://mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0xicN7hTl7ZDbUdaJkX6iauJ8ialRcVjIoXHkYGFqibjZjkC9gWr3S6B9U0kgm9nRUzokt8HwibAB2icEw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

AI眼中是“瓢虫”



![img](https://mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0xicN7hTl7ZDbUdaJkX6iauJ5tbfSPBicGX7yecwX2xGgDTDO8s991nlK8GoqeMCkKdo7QiaDZ5LcHMA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

AI眼中是“日晷”



![img](https://mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0xicN7hTl7ZDbUdaJkX6iauJmCRjicODViczibB4zRhNHOicF0AJ1CNxmaplAQCGib3tIj9ajgNp8pM5b9g/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

AI眼中是“棒球运动员”



![img](https://mmbiz.qpic.cn/mmbiz_jpg/UicQ7HgWiaUb0xicN7hTl7ZDbUdaJkX6iauJz13zvHl3gQlfbnmWN29mGvJx58CrxXVSIdlxQeWiahejd7IrhS7yI1w/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

AI眼中是“人开卡丁车”



## **这些数据有望帮助培养更强大的视觉系统**



在论文中，研究人员称这些数据有望帮助培养更强大的视觉系统。他们解释说，这些图像利用了“深层缺陷”，这些缺陷源于该软件“过度依赖颜色，纹理和背景线索”来识别它所看到的东西。

 

例如，在下面的图像中，AI错误地将左侧的图片当作钉子，这可能是因为图片的木纹背景。在右边的图像中，它们只注意到蜂鸟饲养器，但却错过了没有真正的蜂鸟存在的事实。



![img](https://mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb0xicN7hTl7ZDbUdaJkX6iauJjoHjTbxZiaR0Zsy0kxh6vqvk1wiaFAOQ5icS2IUwZbGqvKsWaMoM3I9Gg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)





下面的四张蜻蜓照片，AI在颜色和纹理上进行分析后，从左到右依次会识别为臭鼬、香蕉、海狮和手套。我们从每张图片中都可以看出AI为什么会犯错误。



![img](https://mmbiz.qpic.cn/mmbiz_png/UicQ7HgWiaUb0xicN7hTl7ZDbUdaJkX6iauJr4CfKvGoy2woicmSUc6oQ2WDtfRV7lWXWeSeDbz0swbibFWk2MSkPXGQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)





AI系统会犯这些错误并不是新闻了。多年来，研究人员一直警告说，利用深度学习创建的视觉系统是“浅薄”和“脆弱”的，它们不会像人一样灵活地理解世界上的一些几乎相同的细微差别。

 

这些AI系统在成千上万的示例图像上进行了训练，但我们通常不知道图片中的哪些确切元素是AI用于做出判断的。

 

一些研究表明，考虑到整体形状和内容，算法不是从整体上看图像，而是专注于特定的纹理和细节。本次数据集中给出的结果似乎支持这种解释，例如，在明亮的表面上显示清晰阴影的图片，会被错误地标识为日晷。



## **AI视觉系统真的没救了？**

 

但这是否意味着这些机器视觉系统没得救了？完全不是。一般这些系统所犯的错误都是小错，比如将排水盖识别为沙井，将货车误认为豪华轿车等。

 

虽然研究人员说这些“自然对抗性的例子”会骗过各种各样的视觉系统，但这并不意味着可以骗过所有系统。许多机器视觉系统非常专业，比如用于识别医学扫描图像中的疾病的那些专门系统。虽然这些系统有着自己的缺点，可能无法理解这个世界和人类，但这并不影响它们发现并诊断癌症。

 

机器视觉系统有时可能会很快且有瑕疵，但通常都会产生结果。这样的研究暴露了机器成像研究中的盲点和空白，我们下一步的任务就是如何填补这些盲点了。



论文地址：

https://arxiv.org/pdf/1907.07174.pdf

代码和数据集：

https://github.com/hendrycks/natural-adv-examples

原文链接：

https://www.theverge.com/2019/7/19/20700481/ai-machine-learning-vision-system-naturally-occuring-adversarial-examples